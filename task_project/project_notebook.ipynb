{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28178622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='darkgrid', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ba65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "32f8dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import torch.utils.data\n",
    "import functools\n",
    "from torch.nn import init\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "209c2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(load_size = 128,\n",
    "#         crop_size = 256,\n",
    "#         preprocess='resize_and_crop',\n",
    "        preprocess='resize',\n",
    "        no_flip=False,\n",
    "        method=transforms.InterpolationMode.BICUBIC,\n",
    "        convert=True):\n",
    "    \n",
    "    transform_list = []\n",
    "\n",
    "    if 'resize' in preprocess:\n",
    "        osize = [load_size, load_size]\n",
    "        transform_list.append(transforms.Resize(osize, method))\n",
    "\n",
    "#     if 'crop' in preprocess:\n",
    "#         transform_list.append(transforms.RandomCrop(opt.crop_size))\n",
    "\n",
    "    if not no_flip:\n",
    "        transform_list.append(transforms.RandomHorizontalFlip())\n",
    "\n",
    "    if convert:\n",
    "        transform_list += [transforms.ToTensor()]\n",
    "        transform_list += [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "    return transforms.Compose(transform_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2289293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "    '.tif', '.TIF', '.tiff', '.TIFF',\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def make_dataset(dir, max_dataset_size=float(\"inf\")):\n",
    "    images = []\n",
    "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(dir)):\n",
    "        for fname in fnames:\n",
    "            if is_image_file(fname):\n",
    "                path = os.path.join(root, fname)\n",
    "                images.append(path)\n",
    "    return images[:min(max_dataset_size, len(images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57dbb53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANDataset(Dataset):\n",
    "    def __init__(self, path, max_dataset_size=float(\"inf\")):\n",
    "#         self.device = device\n",
    "#         self.images = []\n",
    "        self.dir_A = path + 'A'\n",
    "        self.dir_B = path + 'B'\n",
    "        self.A_paths = sorted(make_dataset(self.dir_A))\n",
    "        self.B_paths = sorted(make_dataset(self.dir_B))\n",
    "        self.A_size = len(self.A_paths)  # get the size of dataset A\n",
    "        self.B_size = len(self.B_paths)  # get the size of dataset B\n",
    "        \n",
    "        self.transform = get_transform()\n",
    "        self.serial_batches = True\n",
    "        \n",
    "        self.items = []\n",
    "        for idx in range(max(self.A_size, self.B_size)):\n",
    "            self.items.append(self._get_item(idx))\n",
    "        \n",
    "    def _get_item(self, index):\n",
    "        A_path = self.A_paths[index % self.A_size]  # make sure index is within then range\n",
    "        if self.serial_batches:   # make sure index is within then range\n",
    "            index_B = index % self.B_size\n",
    "        else:   # randomize the index for domain B to avoid fixed pairs.\n",
    "            index_B = random.randint(0, self.B_size - 1)\n",
    "        B_path = self.B_paths[index_B]\n",
    "        A_img = Image.open(A_path).convert('RGB')\n",
    "        B_img = Image.open(B_path).convert('RGB')\n",
    "        # apply image transformation\n",
    "        A = self.transform(A_img)\n",
    "        B = self.transform(B_img)\n",
    "\n",
    "        return {'A': A, 'B': B, 'A_paths': A_path, 'B_paths': B_path}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.items[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\n",
    "        As we have two datasets with potentially different number of images,\n",
    "        we take a maximum of\n",
    "        \"\"\"\n",
    "        return max(self.A_size, self.B_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fe66c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CycleGANDataset('apple2orange/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77600283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "colab_code='''...'''\n",
    "for line in colab_code.split('\\n'):\n",
    "    n_whitespaces = (len(line) - len(line.lstrip()))\n",
    "    print(' ' * n_whitespaces + line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44bdf3",
   "metadata": {},
   "source": [
    "Датасет создали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd45d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_layer(norm_type='instance'):\n",
    "    \"\"\"Return a normalization layer\n",
    "    Parameters:\n",
    "        norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
    "    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
    "    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n",
    "    \"\"\"\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "    elif norm_type == 'none':\n",
    "        def norm_layer(x):\n",
    "            return Identity()\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84eb114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"Define a Resnet block\"\"\"\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Initialize the Resnet block\n",
    "        A resnet block is a conv block with skip connections\n",
    "        We construct a conv block with build_conv_block function,\n",
    "        and implement skip connections in <forward> function.\n",
    "        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Construct a convolutional block.\n",
    "        Parameters:\n",
    "            dim (int)           -- the number of channels in the conv layer.\n",
    "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "            use_bias (bool)     -- if the conv layer uses bias or not\n",
    "        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n",
    "        \"\"\"\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function (with skip connections)\"\"\"\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f654bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        \"\"\"Construct a Resnet-based generator\n",
    "        Parameters:\n",
    "            input_nc (int)      -- the number of channels in input images\n",
    "            output_nc (int)     -- the number of channels in output images\n",
    "            ngf (int)           -- the number of filters in the last conv layer\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers\n",
    "            n_blocks (int)      -- the number of ResNet blocks\n",
    "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=use_bias),\n",
    "                      norm_layer(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3373edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"Initialize network weights.\n",
    "    Parameters:\n",
    "        net (network)   -- network to be initialized\n",
    "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
    "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
    "    work better for some applications. Feel free to try yourself.\n",
    "    \"\"\"\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)  # apply the initialization function <init_func>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1cf55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n",
    "    Parameters:\n",
    "        net (network)      -- the network to be initialized\n",
    "        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "    Return an initialized network.\n",
    "    \"\"\"\n",
    "    if len(gpu_ids) > 0:\n",
    "        assert(torch.cuda.is_available())\n",
    "        net.to(gpu_ids[0])\n",
    "        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
    "    init_weights(net, init_type, init_gain=init_gain)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897e995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Create a generator\n",
    "    Parameters:\n",
    "        input_nc (int) -- the number of channels in input images\n",
    "        output_nc (int) -- the number of channels in output images\n",
    "        ngf (int) -- the number of filters in the last conv layer\n",
    "        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n",
    "        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n",
    "        use_dropout (bool) -- if use dropout layers.\n",
    "        init_type (str)    -- the name of our initialization method.\n",
    "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "    Returns a generator\n",
    "    Our current implementation provides two types of generators:\n",
    "        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n",
    "        The original U-Net paper: https://arxiv.org/abs/1505.04597\n",
    "        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n",
    "        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n",
    "        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n",
    "    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n",
    "    \"\"\"\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netG == 'resnet_9blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9)\n",
    "    elif netG == 'resnet_6blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=6)\n",
    "    elif netG == 'unet_128':\n",
    "        net = UnetGenerator(input_nc, output_nc, 7, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "    elif netG == 'unet_256':\n",
    "        net = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "    else:\n",
    "        raise NotImplementedError('Generator model name [%s] is not recognized' % netG)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b76c1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbe5d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_D(input_nc, ndf, netD, n_layers_D=3, norm='batch', init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    \"\"\"Create a discriminator\n",
    "    Parameters:\n",
    "        input_nc (int)     -- the number of channels in input images\n",
    "        ndf (int)          -- the number of filters in the first conv layer\n",
    "        netD (str)         -- the architecture's name: basic | n_layers | pixel\n",
    "        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n",
    "        norm (str)         -- the type of normalization layers used in the network.\n",
    "        init_type (str)    -- the name of the initialization method.\n",
    "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
    "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
    "    Returns a discriminator\n",
    "    Our current implementation provides three types of discriminators:\n",
    "        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n",
    "        It can classify whether 70×70 overlapping patches are real or fake.\n",
    "        Such a patch-level discriminator architecture has fewer parameters\n",
    "        than a full-image discriminator and can work on arbitrarily-sized images\n",
    "        in a fully convolutional fashion.\n",
    "        [n_layers]: With this mode, you can specify the number of conv layers in the discriminator\n",
    "        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n",
    "        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n",
    "        It encourages greater color diversity but has no effect on spatial statistics.\n",
    "    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n",
    "    \"\"\"\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netD == 'basic':  # default PatchGAN classifier\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer)\n",
    "    elif netD == 'n_layers':  # more options\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers_D, norm_layer=norm_layer)\n",
    "    elif netD == 'pixel':     # classify if each pixel is real or fake\n",
    "        net = PixelDiscriminator(input_nc, ndf, norm_layer=norm_layer)\n",
    "    else:\n",
    "        raise NotImplementedError('Discriminator model name [%s] is not recognized' % netD)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a71335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    \"\"\"This class implements an image buffer that stores previously generated images.\n",
    "    This buffer enables us to update discriminators using a history of generated images\n",
    "    rather than the ones produced by the latest generators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_size):\n",
    "        \"\"\"Initialize the ImagePool class\n",
    "        Parameters:\n",
    "            pool_size (int) -- the size of image buffer, if pool_size=0, no buffer will be created\n",
    "        \"\"\"\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:  # create an empty pool\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        \"\"\"Return an image from the pool.\n",
    "        Parameters:\n",
    "            images: the latest generated images from the generator\n",
    "        Returns images from the buffer.\n",
    "        By 50/100, the buffer will return input images.\n",
    "        By 50/100, the buffer will return images previously stored in the buffer,\n",
    "        and insert the current images to the buffer.\n",
    "        \"\"\"\n",
    "        if self.pool_size == 0:  # if the buffer size is 0, do nothing\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image.data, 0)\n",
    "            if self.num_imgs < self.pool_size:   # if the buffer is not full; keep inserting current images to the buffer\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n",
    "                    random_id = random.randint(0, self.pool_size - 1)  # randint is inclusive\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:       # by another 50% chance, the buffer will return the current image\n",
    "                    return_images.append(image)\n",
    "        return_images = torch.cat(return_images, 0)   # collect all the images and return\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04e25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    \"\"\"Define different GAN objectives.\n",
    "    The GANLoss class abstracts away the need to create the target label tensor\n",
    "    that has the same size as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n",
    "        \"\"\" Initialize the GANLoss class.\n",
    "        Parameters:\n",
    "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
    "            target_real_label (bool) - - label for a real image\n",
    "            target_fake_label (bool) - - label of a fake image\n",
    "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
    "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
    "        \"\"\"\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        self.gan_mode = gan_mode\n",
    "        if gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode in ['wgangp']:\n",
    "            self.loss = None\n",
    "        else:\n",
    "            raise NotImplementedError('gan mode %s not implemented' % gan_mode)\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        \"\"\"Create label tensors with the same size as the input.\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "        Returns:\n",
    "            A label tensor filled with ground truth label, and with the size of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        \"\"\"Calculate loss given Discriminator's output and grount truth labels.\n",
    "        Parameters:\n",
    "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
    "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
    "        Returns:\n",
    "            the calculated loss.\n",
    "        \"\"\"\n",
    "        if self.gan_mode in ['lsgan', 'vanilla']:\n",
    "            target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "            loss = self.loss(prediction, target_tensor)\n",
    "        elif self.gan_mode == 'wgangp':\n",
    "            if target_is_real:\n",
    "                loss = -prediction.mean()\n",
    "            else:\n",
    "                loss = prediction.mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d64180ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, epoch_count, lr_policy='linear', n_epochs=100, n_epochs_decay=100, lr_decay_iters=50):\n",
    "    \"\"\"Return a learning rate scheduler\n",
    "    Parameters:\n",
    "        optimizer          -- the optimizer of the network\n",
    "        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions．　\n",
    "                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n",
    "    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
    "    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
    "    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n",
    "    See https://pytorch.org/docs/stable/optim.html for more details.\n",
    "    \"\"\"\n",
    "    if lr_policy == 'linear':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + epoch_count - n_epochs) / float(n_epochs_decay + 1)\n",
    "            return lr_l\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif opt.lr_policy == 'step':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_decay_iters, gamma=0.1)\n",
    "    elif opt.lr_policy == 'cosine':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=0)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0d682e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANModel:\n",
    "    def __init__(self):\n",
    "        self.gpu_ids = [0]\n",
    "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n",
    "        \n",
    "        norm = 'instance'\n",
    "        pool_size = 50\n",
    "        lr=0.0002\n",
    "        beta1=0.5\n",
    "        \n",
    "        net_G = 'resnet_6blocks'\n",
    "        \n",
    "        self.loss_names = ['D_A', 'G_A', 'cycle_A', 'idt_A', 'D_B', 'G_B', 'cycle_B', 'idt_B']\n",
    "        self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
    "        \n",
    "        \n",
    "        self.netG_A = define_G(input_nc=3,\n",
    "                                         output_nc=3,\n",
    "                                         ngf=64,\n",
    "                                         netG=net_G,\n",
    "                                         norm=norm,\n",
    "                                         use_dropout=True,\n",
    "                                         init_type='normal',\n",
    "                                         init_gain=0.02,\n",
    "                                         gpu_ids=self.gpu_ids)\n",
    "        self.netG_B = define_G(input_nc=3,\n",
    "                                         output_nc=3,\n",
    "                                         ngf=64,\n",
    "                                         netG=net_G,\n",
    "                                         norm=norm,\n",
    "                                         use_dropout=True,\n",
    "                                         init_type='normal',\n",
    "                                         init_gain=0.02,\n",
    "                                         gpu_ids=self.gpu_ids)\n",
    "        \n",
    "        self.netD_A = define_D(input_nc=3,\n",
    "                                        ndf=64,\n",
    "                                        netD='basic',\n",
    "                                        n_layers_D=3, # does not matter\n",
    "                                        norm=norm,\n",
    "                                        init_type='normal',\n",
    "                                        init_gain=0.02,\n",
    "                                        gpu_ids=self.gpu_ids)\n",
    "        self.netD_B = define_D(input_nc=3,\n",
    "                                        ndf=64,\n",
    "                                        netD='basic',\n",
    "                                        n_layers_D=3, # does not matter\n",
    "                                        norm=norm,\n",
    "                                        init_type='normal',\n",
    "                                        init_gain=0.02,\n",
    "                                        gpu_ids=self.gpu_ids)\n",
    "#         if opt.lambda_identity > 0.0:  # only works when input and output images have the same number of channels\n",
    "#             assert 3 == 3\n",
    "\n",
    "        self.fake_A_pool = ImagePool(pool_size)  # create image buffer to store previously generated images\n",
    "        self.fake_B_pool = ImagePool(pool_size)  # create image buffer to store previously generated images\n",
    "        # define loss functions\n",
    "        self.criterionGAN = GANLoss(gan_mode='lsgan').to(self.device)  # define GAN loss.\n",
    "        self.criterionCycle = torch.nn.L1Loss()\n",
    "        self.criterionIdt = torch.nn.L1Loss()\n",
    "        # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.\n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), lr=lr, betas=(beta1, 0.999))\n",
    "        self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), lr=lr, betas=(beta1, 0.999))\n",
    "        \n",
    "        self.optimizers = []\n",
    "        self.optimizers.append(self.optimizer_G)\n",
    "        self.optimizers.append(self.optimizer_D)\n",
    "        \n",
    "    def set_input(self, input):\n",
    "        \"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n",
    "        Parameters:\n",
    "            input (dict): include the data itself and its metadata information.\n",
    "        The option 'direction' can be used to swap domain A and domain B.\n",
    "        \"\"\"\n",
    "        self.real_A = input['A'].to(self.device)\n",
    "        self.real_B = input['B'].to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"\n",
    "        self.fake_B = self.netG_A(self.real_A)  # G_A(A)\n",
    "        self.rec_A = self.netG_B(self.fake_B)   # G_B(G_A(A))\n",
    "        self.fake_A = self.netG_B(self.real_B)  # G_B(B)\n",
    "        self.rec_B = self.netG_A(self.fake_A)   # G_A(G_B(B))\n",
    "    \n",
    "    def setup(self):\n",
    "        self.schedulers = [get_scheduler(optimizer, epoch_count=0) for optimizer in self.optimizers]\n",
    "    \n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        \"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n",
    "        Parameters:\n",
    "            nets (network list)   -- a list of networks\n",
    "            requires_grad (bool)  -- whether the networks require gradients or not\n",
    "        \"\"\"\n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad\n",
    "    \n",
    "    def update_learning_rate(self, print_lr=False):\n",
    "        \"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"\n",
    "        old_lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        for scheduler in self.schedulers:\n",
    "            scheduler.step()\n",
    "\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        if print_lr:\n",
    "            print('learning rate %.7f -> %.7f' % (old_lr, lr))\n",
    "    \n",
    "    def backward_G(self):\n",
    "        \"\"\"Calculate the loss for generators G_A and G_B\"\"\"\n",
    "        lambda_idt = 0.5\n",
    "        lambda_A = 10.0\n",
    "        lambda_B = 10.0\n",
    "        # Identity loss\n",
    "        if lambda_idt > 0:\n",
    "            # G_A should be identity if real_B is fed: ||G_A(B) - B||\n",
    "            self.idt_A = self.netG_A(self.real_B)\n",
    "            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt\n",
    "            # G_B should be identity if real_A is fed: ||G_B(A) - A||\n",
    "            self.idt_B = self.netG_B(self.real_A)\n",
    "            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt\n",
    "        else:\n",
    "            self.loss_idt_A = 0\n",
    "            self.loss_idt_B = 0\n",
    "\n",
    "        # GAN loss D_A(G_A(A))\n",
    "        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)\n",
    "        # GAN loss D_B(G_B(B))\n",
    "        self.loss_G_B = self.criterionGAN(self.netD_B(self.fake_A), True)\n",
    "        # Forward cycle loss || G_B(G_A(A)) - A||\n",
    "        self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n",
    "        # Backward cycle loss || G_A(G_B(B)) - B||\n",
    "        self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n",
    "        # combined loss and calculate gradients\n",
    "        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B + self.loss_idt_A + self.loss_idt_B\n",
    "        self.loss_G.backward()\n",
    "    \n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "        \"\"\"Calculate GAN loss for the discriminator\n",
    "        Parameters:\n",
    "            netD (network)      -- the discriminator D\n",
    "            real (tensor array) -- real images\n",
    "            fake (tensor array) -- images generated by a generator\n",
    "        Return the discriminator loss.\n",
    "        We also call loss_D.backward() to calculate the gradients.\n",
    "        \"\"\"\n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "        # Fake\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "        # Combined loss and calculate gradients\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "    \n",
    "    def backward_D_A(self):\n",
    "        \"\"\"Calculate GAN loss for discriminator D_A\"\"\"\n",
    "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
    "        self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
    "\n",
    "    def backward_D_B(self):\n",
    "        \"\"\"Calculate GAN loss for discriminator D_B\"\"\"\n",
    "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
    "        self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
    "    \n",
    "    def optimize_parameters(self):\n",
    "        \"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"\n",
    "        # forward\n",
    "        self.forward()      # compute fake images and reconstruction images.\n",
    "        # G_A and G_B\n",
    "        self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs\n",
    "        self.optimizer_G.zero_grad()  # set G_A and G_B's gradients to zero\n",
    "        self.backward_G()             # calculate gradients for G_A and G_B\n",
    "        self.optimizer_G.step()       # update G_A and G_B's weights\n",
    "        # D_A and D_B\n",
    "        self.set_requires_grad([self.netD_A, self.netD_B], True)\n",
    "        self.optimizer_D.zero_grad()   # set D_A and D_B's gradients to zero\n",
    "        self.backward_D_A()      # calculate gradients for D_A\n",
    "        self.backward_D_B()      # calculate graidents for D_B\n",
    "        self.optimizer_D.step()  # update D_A and D_B's weights\n",
    "    \n",
    "    def get_current_losses(self):\n",
    "        \"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"\n",
    "        errors_ret = OrderedDict()\n",
    "        for name in self.loss_names:\n",
    "            if isinstance(name, str):\n",
    "                errors_ret[name] = float(getattr(self, 'loss_' + name))  # float(...) works for both scalar tensor and float number\n",
    "        return errors_ret\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5c843d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n"
     ]
    }
   ],
   "source": [
    "model = CycleGANModel()\n",
    "model.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e32cb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = None\n",
    "def train(model, n_epoch):\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(n_epoch+1)):\n",
    "        epoch_start_time = time.time()\n",
    "        model.update_learning_rate(print_lr=True)\n",
    "        for i, data in enumerate(dataset):\n",
    "            model.set_input(data)\n",
    "            model.optimize_parameters()\n",
    "        print(epoch_start_time - time.time())\n",
    "        losses.append(model.get_current_losses())\n",
    "        break\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ac17eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/201 [00:00<?, ?it/s]D:\\anaconda3\\envs\\abbyy\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/201 [01:51<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-111.73006081581116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('D_A', 0.12457944452762604),\n",
       "              ('G_A', 0.2471005767583847),\n",
       "              ('cycle_A', 2.2310426235198975),\n",
       "              ('idt_A', 0.7724971771240234),\n",
       "              ('D_B', 0.1720413863658905),\n",
       "              ('G_B', 0.021594081073999405),\n",
       "              ('cycle_B', 1.974507451057434),\n",
       "              ('idt_B', 1.0232338905334473)])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epoch = 200\n",
    "train(model, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "94faa6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81803eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
